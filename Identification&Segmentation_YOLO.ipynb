{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcsmcmendes/Step_Deep_Learning/blob/main/Identification%26Segmentation_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¯ Object Detection with YOLO and Pre-trained Models\n",
        "\n",
        "Until now, we've used deep learning models to classify entire images â€” deciding what is in the image overall. But what if we want to know where things are?\n",
        "\n",
        "This is where object detection comes in.\n",
        "\n",
        "In this section, weâ€™ll explore YOLO (You Only Look Once) â€” one of the most popular and efficient object detection algorithms. Unlike simple classifiers, YOLO can:\n",
        "\n",
        "    Detect multiple objects in the same image\n",
        "\n",
        "    Predict their bounding boxes\n",
        "\n",
        "    Identify what each object is, and where it is\n",
        "\n",
        "ğŸ’¡ Just like before, weâ€™ll use pre-trained YOLO models, so we donâ€™t need to train anything from scratch. These models already know how to detect common objects (like people, cars, animals, etc.) from large datasets like COCO.\n",
        "\n",
        "ğŸ“¦ What we'll do:\n",
        "\n",
        "    Load a pre-trained YOLO model\n",
        "\n",
        "    Run it on one or more test images\n",
        "\n",
        "    Visualize the detections (bounding boxes + class labels)\n",
        "\n",
        "This will help us understand how deep learning is applied not just to classification, but also to localization and detection â€” a key concept in real-world applications like autonomous vehicles, video surveillance, and agriculture."
      ],
      "metadata": {
        "id": "M3vbD07F9TpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmkxWHfbw3K",
        "outputId": "92ff6801-73b6-4a43-e6f6-f6c8426d8b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.127 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "4zJMK7ChdxVY",
        "outputId": "7874aa6b-a1c4-477f-b121-cdf8c7992329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a COCO-pretrained YOLO12n model\n",
        "model = YOLO(\"yolo12n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PEget7YexAv",
        "outputId": "8b4e760c-4e29-4b06-8db6-01d862c9431c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.34M/5.34M [00:00<00:00, 64.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model.predict(source=\"/content/test_yolo.jpg\",save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AJj1qAsfmwi",
        "outputId": "caf45df2-45f6-4c9c-f2ca-884db2413d3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 5 persons, 10 cars, 1 truck, 2 sports balls, 422.6ms\n",
            "Speed: 18.8ms preprocess, 422.6ms inference, 45.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 18.846242999984497, 'inference': 422.6437539999779, 'postprocess': 45.22919799990177}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(source=\"/content/test_yolo.jpg\",save=True, conf=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW6xCT9OfpMX",
        "outputId": "43d3ad1a-fa6d-421e-bf7e-f10ccd0ca991"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 4 persons, 5 cars, 282.7ms\n",
            "Speed: 5.8ms preprocess, 282.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 5.760873999975047, 'inference': 282.68659100001514, 'postprocess': 2.291386999900169}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'model(...)' syntax is a shorthand for model.predict()\n",
        "# Here we provide the path to the image we want to analyze.\n",
        "# The 'conf=0.6' argument sets the confidence threshold:\n",
        "# only predictions with confidence >= 60% will be shown.\n",
        "results = model(\"/content/test_yolo.jpg\",conf=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtOefNM9gO5D",
        "outputId": "17d9a25c-7ddd-4c40-f9ec-071e6a88c9d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 4 persons, 5 cars, 189.4ms\n",
            "Speed: 3.8ms preprocess, 189.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original image using OpenCV\n",
        "img_path = \"/content/test_yolo.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# Get the list of class names used by the model (e.g., {0: 'person', 1: 'car', ...})\n",
        "class_names = model.names\n",
        "\n",
        "# Create a directory to save the cropped object images\n",
        "output_dir = \"Cropped_objects\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Access detection results: bounding boxes and class indices\n",
        "boxes = results[0].boxes\n",
        "xyxy = boxes.xyxy.cpu().numpy()               # Bounding box coordinates\n",
        "classes = boxes.cls.cpu().numpy().astype(int) # Class IDs as integers\n",
        "\n",
        "# Loop through each detected object\n",
        "for i, (box, cls_id) in enumerate(zip(xyxy, classes)):\n",
        "    x1, y1, x2, y2 = map(int, box)  # Convert coordinates to integers\n",
        "    label = class_names[cls_id]     # Get the class label (e.g., 'dog', 'car')\n",
        "\n",
        "    # Crop the object from the original image using the bounding box\n",
        "    cropped = img[y1:y2, x1:x2]\n",
        "\n",
        "    # Create a filename like 'dog_0.jpg', 'car_1.jpg', etc.\n",
        "    filename = f\"{label}_{i}.jpg\"\n",
        "\n",
        "    # Save the cropped image to the output directory\n",
        "    cv2.imwrite(os.path.join(output_dir, filename), cropped)\n",
        "\n",
        "    print(f\"Saved: {filename}\")  # Log the saved file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TbTMe4XhREw",
        "outputId": "621f176f-62df-499b-ae85-8d2b33fd1e22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: person_0.jpg\n",
            "Saved: person_1.jpg\n",
            "Saved: person_2.jpg\n",
            "Saved: person_3.jpg\n",
            "Saved: car_4.jpg\n",
            "Saved: car_5.jpg\n",
            "Saved: car_6.jpg\n",
            "Saved: car_7.jpg\n",
            "Saved: car_8.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"Cropped_objects\"\n",
        "\n",
        "# 1. Load images and calculate their area\n",
        "image_data = []\n",
        "for filename in os.listdir(input_dir):\n",
        "    path = os.path.join(input_dir, filename)\n",
        "    img = cv2.imread(path)  # Read the image\n",
        "    if img is not None:\n",
        "        h, w = img.shape[:2]           # Get image height and width\n",
        "        area = w * h                   # Compute the area (in pixels)\n",
        "        image_data.append((filename, area, img))  # Store filename, area, and image\n",
        "\n",
        "# 2. Sort the images by area in descending order\n",
        "# This helps us identify the largest detected objects\n",
        "image_data_sorted = sorted(image_data, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 3. Select the top 7 largest images\n",
        "top_7 = image_data_sorted[:7]"
      ],
      "metadata": {
        "id": "f5QW4cwrhrmn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg = YOLO('yolo11n-seg.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qtzyeMxi3p4",
        "outputId": "56de4861-cca1-492a-867b-4f175103eb54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.90M/5.90M [00:00<00:00, 67.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg.predict(source='/content/Cropped_objects/car_4.jpg',save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOAVprIhj8Ab",
        "outputId": "5f19f7da-738e-47de-e39c-542d7f6b6ce1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/Cropped_objects/car_4.jpg: 544x640 1 person, 1 car, 403.8ms\n",
            "Speed: 7.2ms preprocess, 403.8ms inference, 17.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         ...,\n",
              "         [ 98, 130, 119],\n",
              "         [ 98, 132, 121],\n",
              "         [ 98, 132, 121]],\n",
              " \n",
              "        [[ 83,  92,  79],\n",
              "         [ 81,  90,  77],\n",
              "         [ 72,  81,  68],\n",
              "         ...,\n",
              "         [ 93, 125, 114],\n",
              "         [ 93, 125, 114],\n",
              "         [ 90, 124, 113]],\n",
              " \n",
              "        [[ 82,  91,  78],\n",
              "         [ 82,  91,  78],\n",
              "         [ 66,  75,  62],\n",
              "         ...,\n",
              "         [ 96, 128, 117],\n",
              "         [ 91, 123, 112],\n",
              "         [ 90, 122, 111]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[196, 173, 158],\n",
              "         [173, 150, 135],\n",
              "         [124, 101,  86],\n",
              "         ...,\n",
              "         [ 76,  81,  72],\n",
              "         [ 82,  86,  80],\n",
              "         [ 90,  94,  88]],\n",
              " \n",
              "        [[198, 175, 159],\n",
              "         [187, 164, 148],\n",
              "         [126, 103,  88],\n",
              "         ...,\n",
              "         [ 81,  86,  77],\n",
              "         [ 84,  88,  82],\n",
              "         [ 88,  92,  86]],\n",
              " \n",
              "        [[198, 173, 157],\n",
              "         [197, 172, 156],\n",
              "         [127, 104,  88],\n",
              "         ...,\n",
              "         [ 80,  84,  78],\n",
              "         [ 75,  82,  75],\n",
              "         [ 73,  80,  73]]], dtype=uint8)\n",
              " orig_shape: (167, 202)\n",
              " path: '/content/Cropped_objects/car_4.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/predict'\n",
              " speed: {'preprocess': 7.18416800009436, 'inference': 403.84197499997754, 'postprocess': 17.536562000032063}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"segmented_white_background\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
        "\n",
        "# Loop through the top 7 largest cropped objects\n",
        "for i, (filename, _, img) in enumerate(top_7):\n",
        "    results = model_seg(img)  # Run the segmentation model on the image\n",
        "    seg = results[0]          # Get the first (and only) result\n",
        "\n",
        "    # Check if any mask was detected\n",
        "    if seg.masks is None or seg.boxes.conf is None:\n",
        "        print(f\"No segmentation detected for {filename}\")\n",
        "        continue\n",
        "\n",
        "    # Extract segmentation masks and their confidence scores\n",
        "    masks = seg.masks.data.cpu().numpy()       # (N, H, W) â€” binary masks\n",
        "    confs = seg.boxes.conf.cpu().numpy()       # confidence values for each detected object\n",
        "\n",
        "    # Use the mask with the highest confidence\n",
        "    best_idx = confs.argmax()\n",
        "    best_mask = masks[best_idx]\n",
        "\n",
        "    # Resize the mask to match the image size\n",
        "    resized_mask = cv2.resize(best_mask, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Create a white mask (same size as the image)\n",
        "    mask_final = np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
        "\n",
        "    # Convert the resized mask to binary (0 or 255)\n",
        "    binary_mask = (resized_mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Update the mask: set background to 255 (white), object to 0 (keep)\n",
        "    mask_final[binary_mask == 255] = 0\n",
        "\n",
        "    # Apply the binary mask to the image: set white background\n",
        "    result_img = img.copy()\n",
        "    result_img[mask_final == 255] = [255, 255, 255]\n",
        "\n",
        "    # Save the final segmented image with white background\n",
        "    output_path = os.path.join(output_dir, f\"segmented_{filename}\")\n",
        "    cv2.imwrite(output_path, result_img)\n",
        "    print(f\"Saved: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nX_DTTjRDI",
        "outputId": "60ad8e87-d028-4db1-e084-6ca18bb2f5f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 car, 298.0ms\n",
            "Speed: 4.3ms preprocess, 298.0ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_0.jpg\n",
            "\n",
            "0: 640x384 1 person, 2 cars, 284.2ms\n",
            "Speed: 4.1ms preprocess, 284.2ms inference, 16.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_1.jpg\n",
            "\n",
            "0: 640x416 1 person, 1 car, 1 bench, 387.0ms\n",
            "Speed: 4.6ms preprocess, 387.0ms inference, 25.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "Saved: segmented_white_background/segmented_person_2.jpg\n",
            "\n",
            "0: 640x352 1 person, 2 cars, 313.1ms\n",
            "Speed: 3.9ms preprocess, 313.1ms inference, 18.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "Saved: segmented_white_background/segmented_person_3.jpg\n",
            "\n",
            "0: 544x640 1 person, 1 car, 437.2ms\n",
            "Speed: 4.2ms preprocess, 437.2ms inference, 18.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Saved: segmented_white_background/segmented_car_4.jpg\n",
            "\n",
            "0: 608x640 (no detections), 521.7ms\n",
            "Speed: 5.3ms preprocess, 521.7ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No segmentation detected for car_5.jpg\n",
            "\n",
            "0: 480x640 (no detections), 384.8ms\n",
            "Speed: 3.9ms preprocess, 384.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No segmentation detected for car_8.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uea-bitgAtKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}