{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZcDBAL5IFMQay7IVtquKG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcsmcmendes/Step_Deep_Learning/blob/main/Identification%26Segmentation_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmkxWHfbw3K",
        "outputId": "2e3455ca-904d-47e0-d150-1eccf4d0014f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.127-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.127-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.127 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "4zJMK7ChdxVY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a COCO-pretrained YOLO12n model\n",
        "model = YOLO(\"yolo12n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PEget7YexAv",
        "outputId": "6d12d54b-02b5-4c6c-a66e-a3eeca32f186"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.34M/5.34M [00:00<00:00, 65.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model.predict(source=\"/content/test_yolo.jpg\",save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AJj1qAsfmwi",
        "outputId": "3ce56aba-6e49-4c53-bcd1-cdb2ddb18a94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 5 persons, 10 cars, 1 truck, 2 sports balls, 183.9ms\n",
            "Speed: 5.5ms preprocess, 183.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 5.502317000036783, 'inference': 183.86583899996367, 'postprocess': 1.6749289999324901}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(source=\"/content/test_yolo.jpg\",save=True, conf=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW6xCT9OfpMX",
        "outputId": "cf57c345-eb1c-47f2-88ee-a7dcd85511de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 4 persons, 1 car, 357.9ms\n",
            "Speed: 12.7ms preprocess, 357.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 12.725083000077575, 'inference': 357.9315230000475, 'postprocess': 4.306816999928742}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(\"/content/test_yolo.jpg\",conf=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtOefNM9gO5D",
        "outputId": "5a0e3028-fe37-4925-fd0b-cf4b3ff27d7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 5 persons, 6 cars, 171.8ms\n",
            "Speed: 4.8ms preprocess, 171.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results[0] representa a primeira imagem processada\n",
        "boxes = results[0].boxes\n",
        "\n",
        "# Coordenadas (x1, y1, x2, y2) — canto superior esquerdo ao inferior direito\n",
        "xyxy = boxes.xyxy.cpu().numpy()        # Bounding boxes\n",
        "confs = boxes.conf.cpu().numpy()       # Confiança\n",
        "classes = boxes.cls.cpu().numpy()      # Índices das classes detectadas"
      ],
      "metadata": {
        "id": "LG27N6iehFIA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega imagem original com OpenCV\n",
        "img_path = \"/content/test_yolo.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# Lista de nomes das classes (opcional, depende do modelo usado)\n",
        "class_names = model.names  # e.g., {0: 'person', 1: 'bicycle', ...}\n",
        "\n",
        "# Criar pasta de output\n",
        "output_dir = \"Cropped_objects\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Aceder às detecções\n",
        "boxes = results[0].boxes\n",
        "xyxy = boxes.xyxy.cpu().numpy()\n",
        "classes = boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "# Recortar e salvar cada objeto\n",
        "for i, (box, cls_id) in enumerate(zip(xyxy, classes)):\n",
        "    x1, y1, x2, y2 = map(int, box)\n",
        "    label = class_names[cls_id]\n",
        "\n",
        "    cropped = img[y1:y2, x1:x2]\n",
        "    filename = f\"{label}_{i}.jpg\"\n",
        "    cv2.imwrite(os.path.join(output_dir, filename), cropped)\n",
        "\n",
        "    print(f\"Saved: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TbTMe4XhREw",
        "outputId": "cf58b291-1d0a-454d-d33f-038939d2b737"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: person_0.jpg\n",
            "Saved: person_1.jpg\n",
            "Saved: person_2.jpg\n",
            "Saved: person_3.jpg\n",
            "Saved: car_4.jpg\n",
            "Saved: car_5.jpg\n",
            "Saved: car_6.jpg\n",
            "Saved: car_7.jpg\n",
            "Saved: car_8.jpg\n",
            "Saved: person_9.jpg\n",
            "Saved: car_10.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"Cropped_objects\"\n",
        "# 1. Carregar imagens e calcular área\n",
        "image_data = []\n",
        "for filename in os.listdir(input_dir):\n",
        "    path = os.path.join(input_dir, filename)\n",
        "    img = cv2.imread(path)\n",
        "    if img is not None:\n",
        "        h, w = img.shape[:2]\n",
        "        area = w * h\n",
        "        image_data.append((filename, area, img))\n",
        "\n",
        "# 2. Ordenar por área decrescente e pegar as 7 maiores\n",
        "image_data_sorted = sorted(image_data, key=lambda x: x[1], reverse=True)\n",
        "top_7 = image_data_sorted[:7]"
      ],
      "metadata": {
        "id": "f5QW4cwrhrmn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg = YOLO('yolo11n-seg.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qtzyeMxi3p4",
        "outputId": "eb99fc18-ae65-4c55-86ff-18a83c0dc626"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.90M/5.90M [00:00<00:00, 75.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg.predict(source='/content/Cropped_objects/car_4.jpg',save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOAVprIhj8Ab",
        "outputId": "d7cb5b78-975e-47f7-bd3e-c265c7184325"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/Cropped_objects/car_4.jpg: 544x640 1 person, 1 car, 267.9ms\n",
            "Speed: 3.5ms preprocess, 267.9ms inference, 13.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         ...,\n",
              "         [ 98, 130, 119],\n",
              "         [ 98, 132, 121],\n",
              "         [ 98, 132, 121]],\n",
              " \n",
              "        [[ 83,  92,  79],\n",
              "         [ 81,  90,  77],\n",
              "         [ 72,  81,  68],\n",
              "         ...,\n",
              "         [ 93, 125, 114],\n",
              "         [ 93, 125, 114],\n",
              "         [ 90, 124, 113]],\n",
              " \n",
              "        [[ 82,  91,  78],\n",
              "         [ 82,  91,  78],\n",
              "         [ 66,  75,  62],\n",
              "         ...,\n",
              "         [ 96, 128, 117],\n",
              "         [ 91, 123, 112],\n",
              "         [ 90, 122, 111]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[196, 173, 158],\n",
              "         [173, 150, 135],\n",
              "         [124, 101,  86],\n",
              "         ...,\n",
              "         [ 76,  81,  72],\n",
              "         [ 82,  86,  80],\n",
              "         [ 90,  94,  88]],\n",
              " \n",
              "        [[198, 175, 159],\n",
              "         [187, 164, 148],\n",
              "         [126, 103,  88],\n",
              "         ...,\n",
              "         [ 81,  86,  77],\n",
              "         [ 84,  88,  82],\n",
              "         [ 88,  92,  86]],\n",
              " \n",
              "        [[198, 173, 157],\n",
              "         [197, 172, 156],\n",
              "         [127, 104,  88],\n",
              "         ...,\n",
              "         [ 80,  84,  78],\n",
              "         [ 75,  82,  75],\n",
              "         [ 73,  80,  73]]], dtype=uint8)\n",
              " orig_shape: (167, 202)\n",
              " path: '/content/Cropped_objects/car_4.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/predict'\n",
              " speed: {'preprocess': 3.451447000088592, 'inference': 267.8733169998395, 'postprocess': 13.496845999952711}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"segmented_white_background\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i, (filename, _, img) in enumerate(top_7):\n",
        "    results = model_seg(img)\n",
        "\n",
        "    seg = results[0]\n",
        "\n",
        "    if seg.masks is None or seg.boxes.conf is None:\n",
        "        print(f\"No segmentation detected for {filename}\")\n",
        "        continue\n",
        "\n",
        "    # Obter máscaras e confianças\n",
        "    masks = seg.masks.data.cpu().numpy()\n",
        "    confs = seg.boxes.conf.cpu().numpy()\n",
        "\n",
        "    # Melhor deteção (maior confiança)\n",
        "    best_idx = confs.argmax()\n",
        "    best_mask = masks[best_idx]\n",
        "\n",
        "    # Redimensionar a máscara para o tamanho da imagem\n",
        "    resized_mask = cv2.resize(best_mask, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Criar máscara final branca\n",
        "    mask_final = np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
        "\n",
        "    # Aplicar a máscara binária\n",
        "    binary_mask = (resized_mask > 0.5).astype(np.uint8) * 255\n",
        "    mask_final[binary_mask == 255] = 0\n",
        "\n",
        "    # Aplicar a máscara à imagem\n",
        "    result_img = img.copy()\n",
        "    result_img[mask_final == 255] = [255, 255, 255]\n",
        "\n",
        "    output_path = os.path.join(output_dir, f\"segmented_{filename}\")\n",
        "    cv2.imwrite(output_path, result_img)\n",
        "    print(f\"Saved: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nX_DTTjRDI",
        "outputId": "1eb63ff0-aa28-483f-ba8f-932af761952a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 car, 311.8ms\n",
            "Speed: 3.9ms preprocess, 311.8ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_0.jpg\n",
            "\n",
            "0: 640x384 1 person, 2 cars, 241.1ms\n",
            "Speed: 4.5ms preprocess, 241.1ms inference, 13.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_1.jpg\n",
            "\n",
            "0: 640x416 1 person, 1 car, 1 bench, 222.5ms\n",
            "Speed: 4.5ms preprocess, 222.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "Saved: segmented_white_background/segmented_person_2.jpg\n",
            "\n",
            "0: 640x352 1 person, 2 cars, 204.5ms\n",
            "Speed: 3.8ms preprocess, 204.5ms inference, 13.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "Saved: segmented_white_background/segmented_person_3.jpg\n",
            "\n",
            "0: 544x640 1 person, 1 car, 261.2ms\n",
            "Speed: 3.9ms preprocess, 261.2ms inference, 11.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Saved: segmented_white_background/segmented_car_4.jpg\n",
            "\n",
            "0: 608x640 (no detections), 309.1ms\n",
            "Speed: 4.4ms preprocess, 309.1ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No segmentation detected for car_5.jpg\n",
            "\n",
            "0: 640x224 (no detections), 136.9ms\n",
            "Speed: 3.5ms preprocess, 136.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No segmentation detected for person_9.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ],
      "metadata": {
        "id": "BP7orQX4jXGz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para as imagens segmentadas\n",
        "input_dir = \"segmented_white_background\"\n",
        "image_paths = [os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith(\".jpg\")]\n"
      ],
      "metadata": {
        "id": "2O911miNnKAg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7fB8UudnNWD",
        "outputId": "5fcfd0d7-796e-4041-b8ee-4d869f5b8def"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processar cada imagem\n",
        "for path in image_paths:\n",
        "    # Carregar imagem e redimensionar\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Converter para array e adicionar dimensão do batch\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    # Pré-processar conforme o modelo VGG16\n",
        "    image_array = preprocess_input(image_array)\n",
        "\n",
        "    # Fazer predição\n",
        "    preds = model.predict(image_array)\n",
        "\n",
        "    # Decodificar predição (top 3 classes)\n",
        "    decoded = decode_predictions(preds, top=3)[0]\n",
        "\n",
        "    print(f\"\\nImage: {os.path.basename(path)}\")\n",
        "    for i, (imagenet_id, label, prob) in enumerate(decoded):\n",
        "        print(f\"  {i+1}. {label} ({prob * 100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM1MpBXonQl3",
        "outputId": "73671e85-7a35-4ef6-9109-0ef69ad82186"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980ms/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Image: segmented_person_3.jpg\n",
            "  1. trench_coat (20.49%)\n",
            "  2. ski_mask (14.62%)\n",
            "  3. knee_pad (7.54%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
            "\n",
            "Image: segmented_person_2.jpg\n",
            "  1. mortarboard (11.58%)\n",
            "  2. cloak (4.84%)\n",
            "  3. academic_gown (4.57%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
            "\n",
            "Image: segmented_person_0.jpg\n",
            "  1. plastic_bag (23.34%)\n",
            "  2. paper_towel (7.06%)\n",
            "  3. hoopskirt (6.19%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
            "\n",
            "Image: segmented_car_5.jpg\n",
            "  1. cleaver (1.80%)\n",
            "  2. envelope (1.52%)\n",
            "  3. can_opener (1.19%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
            "\n",
            "Image: segmented_person_9.jpg\n",
            "  1. cleaver (1.80%)\n",
            "  2. envelope (1.52%)\n",
            "  3. can_opener (1.19%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
            "\n",
            "Image: segmented_person_1.jpg\n",
            "  1. pedestal (20.46%)\n",
            "  2. stretcher (16.04%)\n",
            "  3. ski (7.03%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step\n",
            "\n",
            "Image: segmented_car_4.jpg\n",
            "  1. totem_pole (10.38%)\n",
            "  2. corkscrew (8.05%)\n",
            "  3. cuirass (3.08%)\n"
          ]
        }
      ]
    }
  ]
}