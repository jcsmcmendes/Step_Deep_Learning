{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcsmcmendes/Step_Deep_Learning/blob/main/Identification%26Segmentation_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎯 Object Detection with YOLO and Pre-trained Models\n",
        "\n",
        "Until now, we've used deep learning models to classify entire images — deciding what is in the image overall. But what if we want to know where things are?\n",
        "\n",
        "This is where object detection comes in.\n",
        "\n",
        "In this section, we’ll explore YOLO (You Only Look Once) — one of the most popular and efficient object detection algorithms. Unlike simple classifiers, YOLO can:\n",
        "\n",
        "    Detect multiple objects in the same image\n",
        "\n",
        "    Predict their bounding boxes\n",
        "\n",
        "    Identify what each object is, and where it is\n",
        "\n",
        "💡 Just like before, we’ll use pre-trained YOLO models, so we don’t need to train anything from scratch. These models already know how to detect common objects (like people, cars, animals, etc.) from large datasets like COCO.\n",
        "\n",
        "📦 What we'll do:\n",
        "\n",
        "    Load a pre-trained YOLO model\n",
        "\n",
        "    Run it on one or more test images\n",
        "\n",
        "    Visualize the detections (bounding boxes + class labels)\n",
        "\n",
        "This will help us understand how deep learning is applied not just to classification, but also to localization and detection — a key concept in real-world applications like autonomous vehicles, video surveillance, and agriculture."
      ],
      "metadata": {
        "id": "M3vbD07F9TpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmkxWHfbw3K",
        "outputId": "92ff6801-73b6-4a43-e6f6-f6c8426d8b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.127 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "4zJMK7ChdxVY",
        "outputId": "7874aa6b-a1c4-477f-b121-cdf8c7992329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a COCO-pretrained YOLO12n model\n",
        "model = YOLO(\"yolo12n.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PEget7YexAv",
        "outputId": "8b4e760c-4e29-4b06-8db6-01d862c9431c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12n.pt to 'yolo12n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.34M/5.34M [00:00<00:00, 64.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model.predict(source=\"/content/test_yolo.jpg\",save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AJj1qAsfmwi",
        "outputId": "caf45df2-45f6-4c9c-f2ca-884db2413d3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 5 persons, 10 cars, 1 truck, 2 sports balls, 422.6ms\n",
            "Speed: 18.8ms preprocess, 422.6ms inference, 45.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 18.846242999984497, 'inference': 422.6437539999779, 'postprocess': 45.22919799990177}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(source=\"/content/test_yolo.jpg\",save=True, conf=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW6xCT9OfpMX",
        "outputId": "43d3ad1a-fa6d-421e-bf7e-f10ccd0ca991"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 4 persons, 5 cars, 282.7ms\n",
            "Speed: 5.8ms preprocess, 282.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 21,  24,  28],\n",
              "         [ 17,  20,  25],\n",
              "         [ 15,  18,  23]],\n",
              " \n",
              "        [[ 19,  24,  22],\n",
              "         [ 19,  24,  22],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 19,  22,  26],\n",
              "         [ 19,  22,  27],\n",
              "         [ 19,  22,  27]],\n",
              " \n",
              "        [[ 19,  24,  23],\n",
              "         [ 19,  24,  23],\n",
              "         [ 21,  23,  23],\n",
              "         ...,\n",
              "         [ 18,  21,  25],\n",
              "         [ 20,  23,  28],\n",
              "         [ 22,  25,  30]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 49,  54,  55],\n",
              "         [ 44,  49,  50],\n",
              "         [ 34,  42,  42],\n",
              "         ...,\n",
              "         [187, 206, 221],\n",
              "         [186, 205, 220],\n",
              "         [183, 202, 217]],\n",
              " \n",
              "        [[ 30,  35,  36],\n",
              "         [ 23,  28,  29],\n",
              "         [ 30,  35,  36],\n",
              "         ...,\n",
              "         [189, 208, 223],\n",
              "         [189, 208, 223],\n",
              "         [187, 206, 221]],\n",
              " \n",
              "        [[ 48,  53,  54],\n",
              "         [ 29,  34,  35],\n",
              "         [ 37,  42,  43],\n",
              "         ...,\n",
              "         [191, 210, 225],\n",
              "         [191, 210, 225],\n",
              "         [189, 208, 223]]], dtype=uint8)\n",
              " orig_shape: (720, 1280)\n",
              " path: '/content/test_yolo.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 5.760873999975047, 'inference': 282.68659100001514, 'postprocess': 2.291386999900169}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The 'model(...)' syntax is a shorthand for model.predict()\n",
        "# Here we provide the path to the image we want to analyze.\n",
        "# The 'conf=0.6' argument sets the confidence threshold:\n",
        "# only predictions with confidence >= 60% will be shown.\n",
        "results = model(\"/content/test_yolo.jpg\",conf=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtOefNM9gO5D",
        "outputId": "17d9a25c-7ddd-4c40-f9ec-071e6a88c9d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/test_yolo.jpg: 384x640 4 persons, 5 cars, 189.4ms\n",
            "Speed: 3.8ms preprocess, 189.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original image using OpenCV\n",
        "img_path = \"/content/test_yolo.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "# Get the list of class names used by the model (e.g., {0: 'person', 1: 'car', ...})\n",
        "class_names = model.names\n",
        "\n",
        "# Create a directory to save the cropped object images\n",
        "output_dir = \"Cropped_objects\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Access detection results: bounding boxes and class indices\n",
        "boxes = results[0].boxes\n",
        "xyxy = boxes.xyxy.cpu().numpy()               # Bounding box coordinates\n",
        "classes = boxes.cls.cpu().numpy().astype(int) # Class IDs as integers\n",
        "\n",
        "# Loop through each detected object\n",
        "for i, (box, cls_id) in enumerate(zip(xyxy, classes)):\n",
        "    x1, y1, x2, y2 = map(int, box)  # Convert coordinates to integers\n",
        "    label = class_names[cls_id]     # Get the class label (e.g., 'dog', 'car')\n",
        "\n",
        "    # Crop the object from the original image using the bounding box\n",
        "    cropped = img[y1:y2, x1:x2]\n",
        "\n",
        "    # Create a filename like 'dog_0.jpg', 'car_1.jpg', etc.\n",
        "    filename = f\"{label}_{i}.jpg\"\n",
        "\n",
        "    # Save the cropped image to the output directory\n",
        "    cv2.imwrite(os.path.join(output_dir, filename), cropped)\n",
        "\n",
        "    print(f\"Saved: {filename}\")  # Log the saved file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TbTMe4XhREw",
        "outputId": "621f176f-62df-499b-ae85-8d2b33fd1e22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: person_0.jpg\n",
            "Saved: person_1.jpg\n",
            "Saved: person_2.jpg\n",
            "Saved: person_3.jpg\n",
            "Saved: car_4.jpg\n",
            "Saved: car_5.jpg\n",
            "Saved: car_6.jpg\n",
            "Saved: car_7.jpg\n",
            "Saved: car_8.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"Cropped_objects\"\n",
        "\n",
        "# 1. Load images and calculate their area\n",
        "image_data = []\n",
        "for filename in os.listdir(input_dir):\n",
        "    path = os.path.join(input_dir, filename)\n",
        "    img = cv2.imread(path)  # Read the image\n",
        "    if img is not None:\n",
        "        h, w = img.shape[:2]           # Get image height and width\n",
        "        area = w * h                   # Compute the area (in pixels)\n",
        "        image_data.append((filename, area, img))  # Store filename, area, and image\n",
        "\n",
        "# 2. Sort the images by area in descending order\n",
        "# This helps us identify the largest detected objects\n",
        "image_data_sorted = sorted(image_data, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 3. Select the top 7 largest images\n",
        "top_7 = image_data_sorted[:7]"
      ],
      "metadata": {
        "id": "f5QW4cwrhrmn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg = YOLO('yolo11n-seg.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qtzyeMxi3p4",
        "outputId": "56de4861-cca1-492a-867b-4f175103eb54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.90M/5.90M [00:00<00:00, 67.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_seg.predict(source='/content/Cropped_objects/car_4.jpg',save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOAVprIhj8Ab",
        "outputId": "5f19f7da-738e-47de-e39c-542d7f6b6ce1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/Cropped_objects/car_4.jpg: 544x640 1 person, 1 car, 403.8ms\n",
            "Speed: 7.2ms preprocess, 403.8ms inference, 17.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         [ 78,  87,  74],\n",
              "         ...,\n",
              "         [ 98, 130, 119],\n",
              "         [ 98, 132, 121],\n",
              "         [ 98, 132, 121]],\n",
              " \n",
              "        [[ 83,  92,  79],\n",
              "         [ 81,  90,  77],\n",
              "         [ 72,  81,  68],\n",
              "         ...,\n",
              "         [ 93, 125, 114],\n",
              "         [ 93, 125, 114],\n",
              "         [ 90, 124, 113]],\n",
              " \n",
              "        [[ 82,  91,  78],\n",
              "         [ 82,  91,  78],\n",
              "         [ 66,  75,  62],\n",
              "         ...,\n",
              "         [ 96, 128, 117],\n",
              "         [ 91, 123, 112],\n",
              "         [ 90, 122, 111]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[196, 173, 158],\n",
              "         [173, 150, 135],\n",
              "         [124, 101,  86],\n",
              "         ...,\n",
              "         [ 76,  81,  72],\n",
              "         [ 82,  86,  80],\n",
              "         [ 90,  94,  88]],\n",
              " \n",
              "        [[198, 175, 159],\n",
              "         [187, 164, 148],\n",
              "         [126, 103,  88],\n",
              "         ...,\n",
              "         [ 81,  86,  77],\n",
              "         [ 84,  88,  82],\n",
              "         [ 88,  92,  86]],\n",
              " \n",
              "        [[198, 173, 157],\n",
              "         [197, 172, 156],\n",
              "         [127, 104,  88],\n",
              "         ...,\n",
              "         [ 80,  84,  78],\n",
              "         [ 75,  82,  75],\n",
              "         [ 73,  80,  73]]], dtype=uint8)\n",
              " orig_shape: (167, 202)\n",
              " path: '/content/Cropped_objects/car_4.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/predict'\n",
              " speed: {'preprocess': 7.18416800009436, 'inference': 403.84197499997754, 'postprocess': 17.536562000032063}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"segmented_white_background\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
        "\n",
        "# Loop through the top 7 largest cropped objects\n",
        "for i, (filename, _, img) in enumerate(top_7):\n",
        "    results = model_seg(img)  # Run the segmentation model on the image\n",
        "    seg = results[0]          # Get the first (and only) result\n",
        "\n",
        "    # Check if any mask was detected\n",
        "    if seg.masks is None or seg.boxes.conf is None:\n",
        "        print(f\"No segmentation detected for {filename}\")\n",
        "        continue\n",
        "\n",
        "    # Extract segmentation masks and their confidence scores\n",
        "    masks = seg.masks.data.cpu().numpy()       # (N, H, W) — binary masks\n",
        "    confs = seg.boxes.conf.cpu().numpy()       # confidence values for each detected object\n",
        "\n",
        "    # Use the mask with the highest confidence\n",
        "    best_idx = confs.argmax()\n",
        "    best_mask = masks[best_idx]\n",
        "\n",
        "    # Resize the mask to match the image size\n",
        "    resized_mask = cv2.resize(best_mask, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Create a white mask (same size as the image)\n",
        "    mask_final = np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
        "\n",
        "    # Convert the resized mask to binary (0 or 255)\n",
        "    binary_mask = (resized_mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Update the mask: set background to 255 (white), object to 0 (keep)\n",
        "    mask_final[binary_mask == 255] = 0\n",
        "\n",
        "    # Apply the binary mask to the image: set white background\n",
        "    result_img = img.copy()\n",
        "    result_img[mask_final == 255] = [255, 255, 255]\n",
        "\n",
        "    # Save the final segmented image with white background\n",
        "    output_path = os.path.join(output_dir, f\"segmented_{filename}\")\n",
        "    cv2.imwrite(output_path, result_img)\n",
        "    print(f\"Saved: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nX_DTTjRDI",
        "outputId": "60ad8e87-d028-4db1-e084-6ca18bb2f5f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 car, 298.0ms\n",
            "Speed: 4.3ms preprocess, 298.0ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_0.jpg\n",
            "\n",
            "0: 640x384 1 person, 2 cars, 284.2ms\n",
            "Speed: 4.1ms preprocess, 284.2ms inference, 16.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Saved: segmented_white_background/segmented_person_1.jpg\n",
            "\n",
            "0: 640x416 1 person, 1 car, 1 bench, 387.0ms\n",
            "Speed: 4.6ms preprocess, 387.0ms inference, 25.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "Saved: segmented_white_background/segmented_person_2.jpg\n",
            "\n",
            "0: 640x352 1 person, 2 cars, 313.1ms\n",
            "Speed: 3.9ms preprocess, 313.1ms inference, 18.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "Saved: segmented_white_background/segmented_person_3.jpg\n",
            "\n",
            "0: 544x640 1 person, 1 car, 437.2ms\n",
            "Speed: 4.2ms preprocess, 437.2ms inference, 18.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Saved: segmented_white_background/segmented_car_4.jpg\n",
            "\n",
            "0: 608x640 (no detections), 521.7ms\n",
            "Speed: 5.3ms preprocess, 521.7ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No segmentation detected for car_5.jpg\n",
            "\n",
            "0: 480x640 (no detections), 384.8ms\n",
            "Speed: 3.9ms preprocess, 384.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No segmentation detected for car_8.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uea-bitgAtKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}